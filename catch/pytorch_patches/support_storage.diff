diff --git a/torch/_tensor.py b/torch/_tensor.py
index 5b325542f9..b502853428 100644
--- a/torch/_tensor.py
+++ b/torch/_tensor.py
@@ -385,18 +385,21 @@ class Tensor(torch._C._TensorBase):
             )
             return (torch._utils._rebuild_wrapper_subclass, arg_wrapper_subclass)
         else:
-            # TODO: Once we decide to break serialization FC, no longer
-            # need to wrap with TypedStorage
-            args = (
-                torch.storage.TypedStorage(
-                    wrap_storage=self.storage().untyped(), dtype=self.dtype
-                ),
-                self.storage_offset(),
-                tuple(self.size()),
-                self.stride(),
-                self.requires_grad,
-                backward_hooks,
-            )  # previously was self._backward_hooks
+            with warnings.catch_warnings():
+                warnings.filterwarnings("ignore",
+                    "Because 64 bit data were casted to 32 bit data on MLU memory, ")
+                # TODO: Once we decide to break serialization FC, no longer
+                # need to wrap with TypedStorage
+                args = (
+                    torch.storage.TypedStorage(
+                        wrap_storage=self.storage().untyped(), dtype=self.dtype
+                    ),
+                    self.storage_offset(),
+                    tuple(self.size()),
+                    self.stride(),
+                    self.requires_grad,
+                    backward_hooks,
+                )  # previously was self._backward_hooks
             return (torch._utils._rebuild_tensor_v2, args)

     def __setstate__(self, state):
diff --git a/torch/_utils.py b/torch/_utils.py
index 8a539d75f5..4a76fb0e16 100644
--- a/torch/_utils.py
+++ b/torch/_utils.py
@@ -142,9 +142,12 @@ def _get_async_or_non_blocking(function_name, non_blocking, kwargs):
 # TODO: Once we decide to break serialization FC, `storage` no longer needs to
 # be a TypedStorage
 def _rebuild_tensor(storage, storage_offset, size, stride):
-    # first construct a tensor with the correct dtype/device
-    t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)
-    return t.set_(storage.untyped(), storage_offset, size, stride)
+    with warnings.catch_warnings():
+        warnings.filterwarnings("ignore",
+            "Because 64 bit data were casted to 32 bit data on MLU memory, ")
+        # first construct a tensor with the correct dtype/device
+        t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)
+        return t.set_(storage.untyped(), storage_offset, size, stride)


 def _rebuild_tensor_v2(
diff --git a/torch/csrc/DynamicTypes.cpp b/torch/csrc/DynamicTypes.cpp
index b3021ffe0d..41d567a4a3 100644
--- a/torch/csrc/DynamicTypes.cpp
+++ b/torch/csrc/DynamicTypes.cpp
@@ -38,6 +38,8 @@ at::DeprecatedTypeProperties* get_type_properties(
     backend = at::Backend::CPU;
   } else if (device_type == at::kCUDA) {
     backend = at::Backend::CUDA;
+  } else if (device_type == at::kMLU) {
+    backend = at::Backend::MLU;
   } else if (device_type == at::kXPU) {
     backend = at::Backend::XPU;
   } else if (device_type == at::kMPS) {
@@ -75,6 +77,20 @@ THPLayout* getTHPLayout(at::Layout layout) {
   return thp_layout;
 }

+PyTypeObject* MLU_loadUntypedStorageTypeObject() {
+  PyObject* MLU_module = PyImport_ImportModule("torch.mlu");
+  TORCH_INTERNAL_ASSERT(MLU_module && PyModule_Check(MLU_module));
+  PyObject* untyped_storage_obj =
+      PyObject_GetAttrString(MLU_module, "UntypedStorage");
+  TORCH_INTERNAL_ASSERT(untyped_storage_obj && PyType_Check(untyped_storage_obj));
+  return reinterpret_cast<PyTypeObject*>(untyped_storage_obj);
+}
+
+PyTypeObject* MLU_getUntypedStorageTypeObject() {
+  static PyTypeObject* untyped_storage_type_obj = MLU_loadUntypedStorageTypeObject();
+  return untyped_storage_type_obj;
+}
+
 PyObject* createPyObject(const at::Storage& storage) {
   if (storage.device_type() != at::DeviceType::Meta &&
       storage.data() == nullptr && storage.nbytes() != 0) {
@@ -82,7 +98,10 @@ PyObject* createPyObject(const at::Storage& storage) {
         false,
         "python bindings to nullptr storage (e.g., from torch.Tensor._make_wrapper_subclass) are currently unsafe and thus disabled.  See https://github.com/pytorch/pytorch/issues/61669 for more details");
   }
-  PyTypeObject* type = reinterpret_cast<PyTypeObject*>(THPStorageClass);
+
+  PyTypeObject* type = (storage.device_type() == at::DeviceType::MLU) ?
+      MLU_getUntypedStorageTypeObject() : reinterpret_cast<PyTypeObject*>(THPStorageClass);
+
   auto obj = THPObjectPtr(type->tp_alloc(type, 0));
   if (!obj)
     throw python_error();
@@ -112,6 +131,12 @@ bool isStorage(PyObject* obj) {
   if (PyObject_TypeCheck(obj, getTypedStorageTypeObject())) {
     return true;
   }
+
+  if (PyObject_HasAttrString(PyImport_ImportModule("torch.mlu"), "UntypedStorage")
+      && PyObject_TypeCheck(obj, MLU_getUntypedStorageTypeObject())) {
+    return true;
+  }
+
   auto obj_type = Py_TYPE(obj);

   return obj_type == reinterpret_cast<PyTypeObject*>(THPStorageClass);
@@ -143,9 +168,10 @@ at::Storage createStorageGetType(
     scalar_type = at::kByte;
     untyped_storage_obj = obj;
   }
-
   if (Py_TYPE(untyped_storage_obj) !=
-      reinterpret_cast<PyTypeObject*>(THPStorageClass)) {
+      reinterpret_cast<PyTypeObject*>(THPStorageClass) &&
+      (PyObject_HasAttrString(PyImport_ImportModule("torch.mlu"), "UntypedStorage") &&
+          PyObject_TypeCheck(untyped_storage_obj, MLU_getUntypedStorageTypeObject()) == 0)) {
     throw TypeError("not a storage '%s'", Py_TYPE(obj)->tp_name);
   }

diff --git a/torch/multiprocessing/reductions.py b/torch/multiprocessing/reductions.py
index 403b28d6a6..326c11afe4 100644
--- a/torch/multiprocessing/reductions.py
+++ b/torch/multiprocessing/reductions.py
@@ -298,7 +298,11 @@ def storage_from_cache(cls, key):
     storage_ref = shared_cache.get(key)
     if storage_ref is None:
         return None
-    return torch.UntypedStorage._new_with_weak_ptr(storage_ref.cdata)
+    tmp_storage = torch.UntypedStorage._new_with_weak_ptr(storage_ref.cdata)
+    if tmp_storage is not None and tmp_storage.device.type == 'mlu':
+        return tmp_storage.mlu()
+    else:
+        return tmp_storage


 def rebuild_storage_fd(cls, df, size):
@@ -351,6 +355,8 @@ def reduce_storage(storage):
     from . import get_sharing_strategy
     if storage.is_cuda:
         raise RuntimeError("Cannot pickle CUDA storage; try pickling a CUDA tensor instead")
+    if storage.device.type == 'mlu':
+        raise RuntimeError("Cannot pickle MLU storage; try pickling a MLU tensor instead")
     elif get_sharing_strategy() == 'file_system':
         metadata = storage._share_filename_cpu_()
         cache_key = metadata[1]


 def rebuild_storage_fd(cls, df, size):
diff --git a/torch/package/package_exporter.py b/torch/package/package_exporter.py
index 81b5e650b5..f12471c264 100644
--- a/torch/package/package_exporter.py
+++ b/torch/package/package_exporter.py
@@ -884,6 +884,10 @@ class PackageExporter:

     def _persistent_id(self, obj):
         if torch.is_storage(obj) or isinstance(obj, torch.storage.TypedStorage):
+            untyped_tuple = (torch.UntypedStorage)
+            if type(obj).__module__.split(".")[0] == 'torch_mlu':
+                import torch_mlu
+                untyped_tuple = (torch.UntypedStorage, torch.mlu.UntypedStorage)
             if isinstance(obj, torch.storage.TypedStorage):
                 # TODO: Once we decide to break serialization FC, we can
                 # remove this case
@@ -892,7 +896,7 @@ class PackageExporter:
                 storage_type = getattr(torch, storage_type_str)
                 storage_numel = obj.size()

-            elif isinstance(obj, torch.UntypedStorage):
+            elif isinstance(obj, untyped_tuple):
                 untyped_storage = obj
                 storage_type = normalize_storage_type(type(storage))
                 storage_numel = storage.nbytes()
@@ -906,6 +910,11 @@ class PackageExporter:
             storage_present = self.storage_context.has_storage(storage)
             storage_id = self.storage_context.get_or_add_storage(storage)
             if not storage_present:
+                # Here we need to carefully handle the 64-bit scenario and make
+                # a copy of of MLU D2H according to the dtype in advance.
+                if storage.device.type == "mlu" and isinstance(obj, torch.storage.TypedStorage) \
+                    and obj.dtype in [torch.double, torch.long, torch.cdouble]:
+                    storage = obj.cpu()._storage
                 if storage.device.type != "cpu":
                     storage = storage.cpu()
                 num_bytes = storage.nbytes()
diff --git a/torch/package/package_importer.py b/torch/package/package_importer.py
index 6efa943f11..faa6c94c66 100644
--- a/torch/package/package_importer.py
+++ b/torch/package/package_importer.py
@@ -10,6 +10,7 @@ from contextlib import contextmanager
 from pathlib import Path
 from typing import Any, BinaryIO, Callable, cast, Dict, Iterable, List, Optional, Union
 from weakref import WeakValueDictionary
+import warnings

 import torch
 from torch.serialization import _get_restore_location, _maybe_decode_ascii
@@ -235,9 +236,12 @@ class PackageImporter(Importer):
                 storage = loaded_storages[key]
                 # TODO: Once we decide to break serialization FC, we can
                 # stop wrapping with TypedStorage
-                return torch.storage.TypedStorage(
-                    wrap_storage=storage.untyped(), dtype=dtype
-                )
+                with warnings.catch_warnings():
+                    warnings.filterwarnings("ignore",
+                    "Because 64 bit data were casted to 32 bit data on MLU memory, ")
+                    return torch.storage.TypedStorage(
+                        wrap_storage=storage.untyped(), dtype=dtype
+                    )
             elif typename == "reduce_package":
                 # to fix BC breaking change, objects on this load path
                 # will be loaded multiple times erroneously
diff --git a/torch/serialization.py b/torch/serialization.py
index 173427edd4..35cd67a4e0 100644
--- a/torch/serialization.py
+++ b/torch/serialization.py
@@ -144,6 +144,11 @@ def _cuda_tag(obj):
         return 'cuda:' + str(obj.device.index)


+def _mlu_tag(obj):
+    if obj.device.type == 'mlu':
+        return 'mlu:' + str(obj.device.index)
+
+
 def _mps_tag(obj):
     if obj.device.type == 'mps':
         return 'mps'
@@ -194,11 +199,38 @@ def _meta_deserialize(obj, location):
     if location == 'meta':
         return torch.UntypedStorage(obj.nbytes(), device='meta')

+def validate_mlu_device(location):
+    device = torch.mlu._utils._get_device_index(location, True)
+
+    if not torch.mlu.is_available():
+        raise RuntimeError('Attempting to deserialize object on a MLU '
+                           'device but torch.mlu.is_available() is False. '
+                           'If you are running on a CPU-only machine, '
+                           'please use torch.load with map_location=torch.device(\'cpu\') '
+                           'to map your storages to the CPU.')
+    device_count = torch.mlu.device_count()
+    if device >= device_count:
+        raise RuntimeError('Attempting to deserialize object on MLU device '
+                           f'{device} but torch.mlu.device_count() is {device_count}. Please use '
+                           'torch.load with map_location to map your storages '
+                           'to an existing device.')
+    return device
+
+
+def _mlu_deserialize(obj, location):
+    if location.startswith('mlu'):
+        device = validate_mlu_device(location)
+        if getattr(obj, "_torch_load_uninitialized", False):
+            with torch.mlu.device(device):
+                return torch.mlu.UntypedStorage(obj.nbytes(), device=torch.device(location))
+        else:
+            return obj.mlu(device)

 register_package(10, _cpu_tag, _cpu_deserialize)
 register_package(20, _cuda_tag, _cuda_deserialize)
 register_package(21, _mps_tag, _mps_deserialize)
 register_package(22, _meta_tag, _meta_deserialize)
+register_package(23, _mlu_tag, _mlu_deserialize)


 def location_tag(storage: Union[Storage, torch.storage.TypedStorage, torch.UntypedStorage]):
@@ -221,7 +253,11 @@ def default_restore_location(storage, location):


 def normalize_storage_type(storage_type):
-    return getattr(torch, storage_type.__name__)
+    if storage_type.__module__.split(".")[0] == 'torch_mlu':
+        import torch_mlu
+        return getattr(torch.mlu, storage_type.__name__)
+    else :
+        return getattr(torch, storage_type.__name__)


 def storage_to_tensor_type(storage):
@@ -460,7 +496,10 @@ def _legacy_save(obj, f, pickle_module, pickle_protocol) -> None:

         if isinstance(obj, torch.storage.TypedStorage) or torch.is_storage(obj):
             storage: torch.UntypedStorage
-
+            untyped_tuple = (torch.UntypedStorage)
+            if type(obj).__module__.split(".")[0] == 'torch_mlu':
+                import torch_mlu
+                untyped_tuple = (torch.UntypedStorage, torch.mlu.UntypedStorage)
             if isinstance(obj, torch.storage.TypedStorage):
                 # TODO: Once we decide to break serialization FC, this case
                 # can be deleted
@@ -471,7 +510,7 @@ def _legacy_save(obj, f, pickle_module, pickle_protocol) -> None:
                 dtype = obj.dtype
                 storage_numel = obj.size()

-            elif isinstance(obj, torch.UntypedStorage):
+            elif isinstance(obj, untyped_tuple):
                 storage = obj
                 storage_dtype = torch.uint8
                 storage_type = normalize_storage_type(type(obj))
@@ -568,6 +607,10 @@ def _legacy_save(obj, f, pickle_module, pickle_protocol) -> None:
     f.flush()
     for key in serialized_storage_keys:
         storage, dtype = serialized_storages[key]
+        # Here we need to carefully handle the 64-bit scenario and make
+        # a copy of MLU D2H according to the dtype in advance.
+        if storage.device.type == 'mlu' and dtype in [torch.double, torch.long, torch.cdouble]:
+            storage = torch.storage.TypedStorage(wrap_storage=storage, dtype=dtype).cpu()._storage
         storage._write_file(f, _should_read_directly(f), True, torch._utils._element_size(dtype))


@@ -618,6 +661,12 @@ def _save(obj, zip_file, pickle_module, pickle_protocol):

             storage_key = id_map.setdefault(storage._cdata, str(len(id_map)))
             location = location_tag(storage)
+            # Here we need to carefully handle the 64-bit scenario and make
+            # a copy of MLU D2H in advance, because after passing this point,
+            # you will not be able to get the dtype information.
+            if isinstance(obj, torch.storage.TypedStorage) and obj.device.type == 'mlu' \
+                and storage_dtype in [torch.double, torch.long, torch.cdouble]:
+                storage = obj.cpu()._storage
             serialized_storages[storage_key] = storage

             return ('storage',
@@ -889,18 +938,43 @@ def _legacy_load(f, map_location, pickle_module, **pickle_load_args):
                     key, location, storage_type = args
                     dtype = storage_type.dtype
                     obj = cast(Storage, torch.UntypedStorage)._new_with_file(f, torch._utils._element_size(dtype))
-                    obj = restore_location(obj, location)
-                    # TODO: Once we decide to break serialization FC, we can
-                    # stop wrapping with TypedStorage
-                    deserialized_objects[key] = torch.storage.TypedStorage(
-                        wrap_storage=obj,
-                        dtype=dtype)
+
+                    # Here we need to carefully handle the 64-bit scenario.
+                    # Currently we deliberately delay MLU H2D copy, because
+                    # after passing this point, we can get the dtype information.
+                    res, mapped_location = _get_mapped_location(obj, map_location, location)
+                    if res == None:
+                        if mapped_location.startswith('mlu') and \
+                            dtype in [torch.double, torch.long, torch.cdouble]:
+                            obj_real = obj
+                            obj = cast(Storage, torch.UntypedStorage(obj.nbytes()))
+                            obj._torch_load_uninitialized = True
+                        # TODO: Once we decide to break serialization FC, we can
+                        # stop wrapping with TypedStorage
+                        deserialized_objects[key] = torch.storage.TypedStorage(
+                            wrap_storage=restore_location(obj, location),
+                            dtype=dtype)
+                        # MLU 64-bit H2D
+                        if getattr(obj, "_torch_load_uninitialized", False):
+                            deserialized_objects[key].copy_(torch.storage.TypedStorage(
+                                wrap_storage=obj_real, dtype=dtype))
+                    else:
+                        # TODO: Once we decide to break serialization FC, we can
+                        # stop wrapping with TypedStorage
+                        deserialized_objects[key] = torch.storage.TypedStorage(
+                            wrap_storage=res,
+                            dtype=dtype)

                 storage_views = pickle_module.load(f, **pickle_load_args)
                 for target_cdata, root_cdata, offset, numel in storage_views:
                     root = deserialized_objects[root_cdata]
                     element_size = torch._utils._element_size(root.dtype)
                     offset_bytes = offset * element_size
+                    # Here we need to carefully handle the 64-bit scenario.
+                    # Only half of the mlu untyped storage is effective.
+                    if root.device.type == 'mlu' \
+                        and root.dtype in [torch.double, torch.long, torch.cdouble]:
+                        offset_bytes = offset_bytes / 2
                     # TODO: Once we decide to break serialization FC, we can
                     # stop wrapping with TypedStorage
                     deserialized_objects[target_cdata] = torch.storage.TypedStorage(
@@ -962,6 +1036,11 @@ def _legacy_load(f, map_location, pickle_module, **pickle_load_args):
             if view_metadata is not None:
                 view_key, offset, view_size = view_metadata
                 offset_bytes = offset * torch._utils._element_size(dtype)
+                # Here we need to carefully handle the 64-bit scenario.
+                # Only half of the mlu untyped storage is effective.
+                if typed_storage.device.type == 'mlu' \
+                    and dtype in [torch.double, torch.long, torch.cdouble]:
+                    offset_bytes = offset_bytes / 2
                 view_size_bytes = view_size * torch._utils._element_size(dtype)
                 if view_key not in deserialized_objects:
                     # TODO: Once we decide to break serialization FC, we can
@@ -1017,9 +1096,19 @@ def _legacy_load(f, map_location, pickle_module, **pickle_load_args):
     for key in deserialized_storage_keys:
         assert key in deserialized_objects
         typed_storage = deserialized_objects[key]
-        typed_storage._storage._set_from_file(
-            f, offset, f_should_read_directly,
-            torch._utils._element_size(typed_storage.dtype))
+        # MLU 64-bit H2D
+        if typed_storage.device.type == 'mlu' \
+            and typed_storage.dtype in [torch.double, torch.long, torch.cdouble]:
+            tmp_storage = torch.UntypedStorage(typed_storage.nbytes())
+            tmp_storage._set_from_file(
+                f, offset, f_should_read_directly,
+                torch._utils._element_size(typed_storage.dtype))
+            typed_storage.copy_(torch.storage.TypedStorage(
+                wrap_storage=tmp_storage, dtype=typed_storage.dtype))
+        else:
+            typed_storage._storage._set_from_file(
+                f, offset, f_should_read_directly,
+                torch._utils._element_size(typed_storage.dtype))
         if offset is not None:
             offset = f.tell()

@@ -1061,6 +1150,19 @@ def _get_restore_location(map_location):
             return result
     return restore_location

+def _get_mapped_location(storage, map_location, location):
+    if map_location is None:
+        return None, location
+    elif isinstance(map_location, dict):
+        return None, map_location.get(location, location)
+    elif isinstance(map_location, _string_classes):
+        return None, map_location
+    elif isinstance(map_location, torch.device):
+        return None, str(map_location)
+    else:
+        result = map_location(storage, location)
+        return result, location
+
 class StorageType():
     def __init__(self, name):
         self.dtype = _get_dtype_from_pickle_storage_type(name)
@@ -1077,11 +1179,32 @@ def _load(zip_file, map_location, pickle_module, pickle_file='data.pkl', **pickl
         name = f'data/{key}'

         storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage).storage().untyped()
-        # TODO: Once we decide to break serialization FC, we can
-        # stop wrapping with TypedStorage
-        loaded_storages[key] = torch.storage.TypedStorage(
-            wrap_storage=restore_location(storage, location),
-            dtype=dtype)
+
+        # Here we need to carefully handle the 64-bit scenario.
+        # Currently we deliberately delay MLU H2D copy, because
+        # after passing this point, we can get the dtype information.
+        res, mapped_location = _get_mapped_location(storage, map_location, location)
+        if res == None:
+            if mapped_location.startswith('mlu') and \
+                dtype in [torch.double, torch.long, torch.cdouble]:
+                storage_real = storage
+                storage = cast(Storage, torch.UntypedStorage(numel))
+                storage._torch_load_uninitialized = True
+            # TODO: Once we decide to break serialization FC, we can
+            # stop wrapping with TypedStorage
+            loaded_storages[key] = torch.storage.TypedStorage(
+                wrap_storage=restore_location(storage, location),
+                dtype=dtype)
+            # MLU 64-bit H2D
+            if getattr(storage, "_torch_load_uninitialized", False):
+                loaded_storages[key].copy_(torch.storage.TypedStorage(
+                    wrap_storage=storage_real, dtype=dtype))
+        else:
+            # TODO: Once we decide to break serialization FC, we can
+            # stop wrapping with TypedStorage
+            loaded_storages[key] = torch.storage.TypedStorage(
+                wrap_storage=res,
+                dtype=dtype)

     def persistent_load(saved_id):
         assert isinstance(saved_id, tuple)
@@ -1091,7 +1214,11 @@ def _load(zip_file, map_location, pickle_module, pickle_file='data.pkl', **pickl
         assert typename == 'storage', \
             f"Unknown typename for persistent_load, expected 'storage' but got '{typename}'"
         storage_type, key, location, numel = data
-        if storage_type is torch.UntypedStorage:
+        untyped_list = [torch.UntypedStorage]
+        if 'mlu' in location:
+            import torch_mlu
+            untyped_list.append(torch.mlu.UntypedStorage)
+        if storage_type in untyped_list:
             dtype = torch.uint8
         else:
             dtype = storage_type.dtype
diff --git a/torch/storage.py b/torch/storage.py
index 8e35973405..5520f1aec2 100644
--- a/torch/storage.py
+++ b/torch/storage.py
@@ -1,3 +1,4 @@
+import warnings
 import io

 import torch
@@ -31,6 +32,8 @@ class _StorageBase(object):

     def type(self, dtype: str = None, non_blocking: bool = False) -> T: ...  # noqa: E704
     def cuda(self, device=None, non_blocking=False, **kwargs) -> T: ...  # noqa: E704
+    # Implemented in catch/torch_mlu/storage.py
+    def mlu(self, device=None, non_blocking=False, **kwargs) -> T: ...  # noqa: E704
     def element_size(self) -> int: ...  # noqa: E704
     def get_device(self) -> int: ...  # noqa: E704
     def data_ptr(self) -> int: ...  # noqa: E704
@@ -66,6 +69,8 @@ class _StorageBase(object):
     def _free_weak_ref(cls, *args, **kwargs): ...  # noqa: E704
     @property
     def is_cuda(self): ...  # noqa: E704
+    @property
+    def is_mlu(self): ...  # noqa: E704
     @classmethod
     def from_file(cls, filename, shared, nbytes) -> T: ...  # noqa: E704
     @classmethod
@@ -236,6 +241,10 @@ class UntypedStorage(torch._C.StorageBase, _StorageBase):
     def is_cuda(self):
         return self.device.type == 'cuda'

+    @property
+    def is_mlu(self):
+        return self.device.type == 'mlu'
+
 def _load_from_bytes(b):
     return torch.load(io.BytesIO(b))

@@ -296,8 +305,10 @@ def _get_storage_from_sequence(sequence, dtype, device):
             sequence,
             dtype=dtype,
             device=device)
-
-    return tmp_tensor.storage().untyped()
+    with warnings.catch_warnings():
+        warnings.filterwarnings("ignore",
+            "Because 64 bit data were casted to 32 bit data on MLU memory, ")
+        return tmp_tensor.storage().untyped()

 def _isint(x):
     if HAS_NUMPY:
@@ -350,11 +361,13 @@ class TypedStorage:
                     raise TypeError(
                         arg_error_msg +
                         f"\nArgument type not recognized: {type(args[0])}")
-
-                return TypedStorage(
-                    *args,
-                    dtype=cls.dtype,
-                    device='cuda' if cls.__module__ == 'torch.cuda' else 'cpu')
+                if cls.__module__ == 'torch_mlu':
+                    return TypedStorage(*args, dtype=cls.dtype, device='mlu')
+                else:
+                    return TypedStorage(
+                        *args,
+                        dtype=cls.dtype,
+                        device='cuda' if cls.__module__ == 'torch.cuda' else 'cpu')

             else:
                 if len(args) != 0:
@@ -362,14 +375,15 @@ class TypedStorage:
                         arg_error_msg +
                         "\nNo positional arguments should be given when using "
                         "'wrap_storage'")
-
-                if not isinstance(wrap_storage, torch.UntypedStorage):
+                module_untyped = (torch.UntypedStorage, torch.mlu.UntypedStorage) if hasattr(
+                torch.mlu, 'UntypedStorage') else (torch.UntypedStorage)
+                if not isinstance(wrap_storage, module_untyped):
                     raise TypeError(
                         arg_error_msg +
                         f"\nArgument 'wrap_storage' must be UntypedStorage, but got {type(wrap_storage)}")

                 cls_device = 'cuda' if cls.__module__ == 'torch.cuda' else 'cpu'
-
+                cls_device = 'mlu' if cls.__module__ == 'torch_mlu' else cls_device
                 if wrap_storage.device.type != cls_device:
                     raise RuntimeError(
                         arg_error_msg +
@@ -413,8 +427,9 @@ class TypedStorage:
                     "\nArgument 'device' should not be specified when 'wrap_storage' is given")

             self.dtype = dtype
-
-            if not isinstance(wrap_storage, torch.UntypedStorage):
+            module_untyped = (torch.UntypedStorage, torch.mlu.UntypedStorage) if hasattr(
+                torch.mlu, 'UntypedStorage') else (torch.UntypedStorage)
+            if not isinstance(wrap_storage, module_untyped):
                 raise TypeError(
                     arg_error_msg +
                     f"\nArgument 'wrap_storage' must be UntypedStorage, but got {type(wrap_storage)}")
@@ -428,13 +443,20 @@ class TypedStorage:
             if self.dtype in [torch.quint8, torch.quint4x2, torch.quint2x4, torch.qint32, torch.qint8]:
                 if device.type == 'cuda':
                     raise RuntimeError("Cannot create CUDA storage with quantized dtype")
+                if device.type == 'mlu':
+                    raise RuntimeError("Cannot create MLU storage with quantized dtype")

             if len(args) == 0:
-                self._storage = torch.UntypedStorage(device=device)
+                self._storage = torch.UntypedStorage(
+                    device=device) if device.type != 'mlu' else torch.mlu.UntypedStorage(
+                        device=device)

             elif len(args) == 1:
                 if _isint(args[0]):
-                    self._storage = torch.UntypedStorage(int(args[0]) * self.element_size(), device=device)
+                    self._storage = torch.UntypedStorage(
+                        int(args[0]) * self.element_size(),
+                        device=device) if device.type != 'mlu' else torch.mlu.UntypedStorage(
+                            int(args[0]) * self.element_size(), device=device)
                 elif isinstance(args[0], collections.abc.Sequence):
                     self._storage = _get_storage_from_sequence(args[0], self.dtype, device)
                 else:
@@ -452,12 +474,20 @@ class TypedStorage:
     def is_cuda(self):
         return self.device.type == 'cuda'

+    @property
+    def is_mlu(self):
+        return self.device.type == 'mlu'
+
     def untyped(self):
         """Returns the internal :class:`torch.UntypedStorage`"""
+        if self.device.type == 'mlu' and self.dtype in [torch.float64, torch.int64, torch.complex128]:
+            warnings.warn("Because 64 bit data were casted to 32 bit data on MLU memory, "
+                "the behavior of getting a untyped storage from a 64-bit typed storage is dangerous.")
         return self._storage

     def _new_wrapped_storage(self, untyped_storage):
-        assert type(untyped_storage) == torch.UntypedStorage
+        assert (type(untyped_storage) == torch.UntypedStorage
+                or type(untyped_storage) == torch.mlu.UntypedStorage)

         if type(self) == TypedStorage:
             return TypedStorage(wrap_storage=untyped_storage, dtype=self.dtype)
@@ -540,10 +570,16 @@ class TypedStorage:
                 dtype=interpret_dtypes[self.dtype])[idx]

         idx_wrapped = self._maybe_wrap_index(idx)
+
         tmp_tensor = torch.tensor([], dtype=self.dtype, device=self.device).set_(self)
         return tmp_tensor[idx_wrapped].item()

     def copy_(self, source: T, non_blocking: bool = None):
+        if self.device.type == 'mlu' or source.device.type == 'mlu':
+            tmp_tensor_1 = torch.tensor([], dtype=self.dtype, device=self.device).set_(self)
+            tmp_tensor_2 = torch.tensor([], dtype=source.dtype, device=source.device).set_(source)
+            tmp_tensor_1.copy_(tmp_tensor_2)
+            return self
         self._storage.copy_(source.untyped(), non_blocking)
         return self

@@ -568,6 +604,18 @@ class TypedStorage:
         cuda_storage: torch.UntypedStorage = self._storage.cuda(device, non_blocking, **kwargs)
         return self._new_wrapped_storage(cuda_storage)

+    def mlu(self, device=None, non_blocking=False, **kwargs) -> T:
+        if self.dtype in [torch.quint8, torch.quint4x2, torch.quint2x4, torch.qint32, torch.qint8]:
+            raise RuntimeError("Cannot create MLU storage with quantized dtype")
+        elif self.dtype in [torch.float64, torch.int64, torch.complex128]:
+            if device is None:
+                device = torch.mlu.current_device()
+            mlu_untyped = _get_storage_from_sequence(self.tolist(), self.dtype, device)
+            return self._new_wrapped_storage(mlu_untyped)
+        else:
+            mlu_untyped = torch.mlu.UntypedStorage.mlu(self, device, non_blocking, **kwargs)
+            return self._new_wrapped_storage(mlu_untyped)
+
     def element_size(self):
         return torch._utils._element_size(self.dtype)

@@ -609,10 +657,13 @@ class TypedStorage:

     def cpu(self):
         """Returns a CPU copy of this storage if it's not already on the CPU"""
+        if self.device.type == 'mlu':
+            return torch.tensor([], dtype=self.dtype, device=self.device).set_(self).cpu().storage()
         return self._new_wrapped_storage(self._storage.cpu())

     def pin_memory(self):
         """Coppies the  storage to pinned memory, if it's not already pinned."""
+        self._storage = torch.mlu.UntypedStorage(self._storage.size()).copy_(self._storage, False)
         return self._new_wrapped_storage(self._storage.pin_memory())

     def share_memory_(self):
@@ -632,10 +683,12 @@ class TypedStorage:
         if device is None:
             device = 'cpu'
         device = torch.device(device)
-        untyped_storage = torch.UntypedStorage._new_shared(size * self.element_size(), device=device)
-        return TypedStorage(
-            wrap_storage=untyped_storage,
-            dtype=self.dtype)
+        untyped_storage = None
+        if device.type == 'mlu':
+            untyped_storage = torch.mlu.UntypedStorage._new_shared(size * self.element_size(), device=device)
+        else:
+            untyped_storage = torch.UntypedStorage._new_shared(size * self.element_size(), device=device)
+        return TypedStorage(wrap_storage=untyped_storage,dtype=self.dtype)

     @property
     def _cdata(self):
@@ -831,10 +884,11 @@ class TypedStorage:

         storage_name = _dtype_to_storage_type_map()[self.dtype]

-        if self.device.type not in ['cpu', 'cuda']:
+        if self.device.type not in ['cpu', 'cuda', 'mlu']:
             return None

         module = torch if self.device.type == 'cpu' else torch.cuda
+        module = torch.mlu if self.device.type == 'mlu' else module

         try:
             return getattr(module, storage_name)
@@ -850,6 +904,7 @@ class _LegacyStorageMeta(type):
     def __instancecheck__(cls, instance):
         if type(instance) == TypedStorage:
             cls_device = 'cuda' if cls.__module__ == 'torch.cuda' else 'cpu'
+            cls_device = 'mlu' if cls.__module__ == 'torch_mlu' else cls_device
             return (cls_device == instance.device.type) and (cls.dtype == instance.dtype)
         return False
